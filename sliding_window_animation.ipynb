{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9QgTlmaqO844",
      "metadata": {
        "id": "9QgTlmaqO844",
        "tags": [],
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "! pip install ripser persim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ripser, persim, warnings\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation, PillowWriter\n",
        "from joblib import Parallel, delayed\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "MBgmAcTyrX3W"
      },
      "id": "MBgmAcTyrX3W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a9b34833-1120-44bc-9fb1-bb8b572c279c",
      "metadata": {
        "id": "a9b34833-1120-44bc-9fb1-bb8b572c279c"
      },
      "source": [
        "## Function that returns bottleneck distance and optionally plots persistence diagram matchings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b171094-ce93-4712-8e63-e8ae6e277063",
      "metadata": {
        "id": "2b171094-ce93-4712-8e63-e8ae6e277063"
      },
      "outputs": [],
      "source": [
        "def getDist(feature, homologyGroup, matching=False, dgm=False):\n",
        "  '''\n",
        "  Takes a 2D array with columns x,y\n",
        "  and integer for homology group\n",
        "  TODO: accept 3D time series\n",
        "  '''\n",
        "                  # Line has same width and number of X points as feature...          but with y values at zero\n",
        "  line = np.array([np.linspace(min(feature[:,0]),max(feature[:,0]),len(feature[:,0])),np.zeros_like(feature[:,1])])\n",
        "  feature_dgm = ripser.ripser(feature)['dgms'][homologyGroup]\n",
        "  line_dgm = ripser.ripser(line.T)['dgms'][homologyGroup]\n",
        "\n",
        "  # Ignore warnings for dgm with non-finite death times\n",
        "  with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", message=r\"dgm[12] has points with non-finite death times;ignoring those points\")\n",
        "    if dgm:\n",
        "      persim.bottleneck_matching(feature_dgm, line_dgm, persim.bottleneck( \\\n",
        "        feature_dgm, line_dgm, matching=True)[1], labels=['feature', 'line'])\n",
        "\n",
        "    if matching:\n",
        "      return feature_dgm, line_dgm, persim.bottleneck(feature_dgm, line_dgm, matching=True)[1]\n",
        "    else:\n",
        "      return persim.bottleneck(feature_dgm, line_dgm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions for bugfixing and parallelization"
      ],
      "metadata": {
        "id": "ahoTqrQhIXry"
      },
      "id": "ahoTqrQhIXry"
    },
    {
      "cell_type": "code",
      "source": [
        "def setupBuff(data):\n",
        "  '''\n",
        "  Since we have periodic boundary conditions, we need copy the point cloud on\n",
        "  each end of the domain before looping over the original middle section\n",
        "  * time, timeRange are not included in this function *\n",
        "  '''\n",
        "  if data.ndim==2:\n",
        "    x,y = data.T\n",
        "    xRange = x.max() - x.min()\n",
        "    lbuff, rbuff = data.copy(), data.copy()\n",
        "    lbuff[:, 0] -= xRange\n",
        "    rbuff[:, 0] += xRange\n",
        "    buff = np.vstack((lbuff, data, rbuff))\n",
        "  elif data.ndim==3:\n",
        "    # Assumes dims are time,x,y\n",
        "    x, y = data.reshape(data.shape[1]*data.shape[2],2).T\n",
        "    xRange = x.max() - x.min()\n",
        "    buff = np.zeros((data.shape[1]*data.shape[2],2))\n",
        "    buffx,buffy = buff.T\n",
        "    for t in range(data.shape[0]):\n",
        "      lbuff, rbuff = data[t].copy(), data[t].copy()\n",
        "      lbuff[:, 0] -= xRange\n",
        "      rbuff[:, 0] += xRange\n",
        "      buff[t*data.shape[1]:(t+1)*data.shape[1]] = np.vstack((lbuff, data[t], rbuff))\n",
        "  #buffx,buffy = buff.T\n",
        "  return x, y, xRange, buff#, buffx, buffy\n",
        "\n",
        "                                        # 2D is default\n",
        "def getWindow(pos, offset, buff, time=None, tPos=None, tOffset=None):\n",
        "  buffx = buff.T[0]\n",
        "  if data.ndim==2:\n",
        "    window = buff[(buffx>pos-offset) & (buffx<pos+offset)]\n",
        "    # Try to prevent 1-cell disconnected components on the edges\n",
        "    # This is a rare edge case - this mostly doesn't do anything\n",
        "    # Doesn't seem to matter for homology groups greater than zero\n",
        "    window[:,1][window[:,0]==window[0,0]] = window[0,1].min()\n",
        "    window[:,1][window[:,0]==window[-1,0]] = window[-1,1].min()\n",
        "  elif data.ndim==3:\n",
        "    raise ValueError(\"Windows for 3D time series not yet implemented\")\n",
        "    # TODO: figure out how to select 3D window\n",
        "    window = buff[(buffx>pos-offset) & (buffx<pos+offset)]\n",
        "    # Try to prevent 1-cell disconnected components on the edges\n",
        "  return window\n",
        "\n",
        "def distsAtPos(pos, offsets, homologyGroups, buff):\n",
        "  '''\n",
        "  Gets bottleneck distances at an alongshore position given window offsets, homology groups, and buffered data\n",
        "  '''\n",
        "  print(pos, flush = True)\n",
        "  # Each parallel job will return a row of bottleneck distances for all offsets and homology groups\n",
        "  posDists = np.zeros((len(offsets), len(homologyGroups)))\n",
        "  for offsetIdx, offset in enumerate(offsets):\n",
        "    # TODO : 3D case\n",
        "    window = getWindow(pos, offset, buff)\n",
        "    for hgIdx,hg in enumerate(homologyGroups):\n",
        "        posDists[offsetIdx,hgIdx] = getDist(window, hg)\n",
        "  # Be careful of this indent! Otherwise it will return only the first offset\n",
        "  return posDists"
      ],
      "metadata": {
        "id": "wHsLbjD0PVOz"
      },
      "id": "wHsLbjD0PVOz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9f4c0fb2-b51c-4623-ae6a-757d9ee50c00",
      "metadata": {
        "id": "9f4c0fb2-b51c-4623-ae6a-757d9ee50c00"
      },
      "source": [
        "## Function that loops over data and stores bottleneck distances in a higher order array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_windows_par(pointCloud, homologyGroups=None, dx=None, maxWindow=None, minWindow=None, step=None):\n",
        "  '''\n",
        "  Accepts 2D snapshots\n",
        "  TODO: accept 3D time series\n",
        "  When this is done, each alongshore position has a spectrum of bottleneck\n",
        "    distances for a range of window sizes centered on those positions\n",
        "  '''\n",
        "  x, y, xRange, buff = setupBuff(pointCloud)\n",
        "  if pointCloud.ndim==3:\n",
        "    # Create array of timestep values for each x,y row in buff\n",
        "           # TODO: Use absolute units: time*dt+startTime\n",
        "    time = np.repeat(range(pointCloud.shape[0]),pointCloud.shape[1])\n",
        "    timeRange = time.max() - time.min()\n",
        "\n",
        "  # Prefer input parameters. Defaults are maximum range and resolution (slow).\n",
        "  if homologyGroups is None:\n",
        "    homologyGroups = list(range(pointCloud.ndim))\n",
        "  if dx is None:\n",
        "    dx = np.diff(x)[np.diff(x)>0].min() # cell size\n",
        "  # how much to increment between adjacent window sizes\n",
        "  if step is None:\n",
        "    step = dx\n",
        "  # window widths\n",
        "  if maxWindow is None:\n",
        "    maxWindow = xRange\n",
        "  if minWindow is None:\n",
        "    minWindow = step   # Anything higher creates an arbitrary cutoff\n",
        "\n",
        "  # I *think* these are correct... but don't sue me\n",
        "  positions = dx*np.arange(xRange//dx+2)+x.min()\n",
        "  offsets = step*np.arange(1,maxWindow//step+1)/2\n",
        "  offsets = offsets[offsets>=minWindow/2]\n",
        "\n",
        "  print(f\"Positions: {positions}\")\n",
        "  print(f\"Offsets: {offsets}\")\n",
        "  print(f\"Homology Groups: {homologyGroups}\")\n",
        "\n",
        "  # Create a partial function for distsAtPos with fixed arguments\n",
        "  distsAtPos_partial = partial(distsAtPos, offsets=offsets, homologyGroups=homologyGroups, buff=buff)\n",
        "\n",
        "  # Execute the inner loop in parallel for each position\n",
        "  # The results will be a list of arrays, where each array corresponds to a column of 'dists'\n",
        "  # Parallel() and delayed() each return a function called by Parallel()() and delayed()()\n",
        "  allPosDists = Parallel(n_jobs=-1, backend='threading')( # -1 means all; backend='threading' necessary for print (at least in colab)\n",
        "      # delayed() parallelizes the list comprehension (can't just unpack args, expects multiple calls)\n",
        "      delayed(distsAtPos_partial)(pos) for pos in positions)\n",
        "\n",
        "  # Reshape the results into the final dists array\n",
        "  # allPosDists is a list of arrays, each array is (len(offsets), len(homologyGroups))\n",
        "  # Need (len(homologyGroups), len(offsets), len(positions)))\n",
        "  # Rearrange dists dims so that homology group is outermost\n",
        "  dists = np.array(allPosDists).transpose(2,1,0) # Idk why this is different from non-parallel dists\n",
        "\n",
        "  return dists, positions, offsets*2, homologyGroups"
      ],
      "metadata": {
        "id": "8Cx0lXUosZeo"
      },
      "id": "8Cx0lXUosZeo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ideas for more plots"
      ],
      "metadata": {
        "id": "NcBwWSjFFWR6"
      },
      "id": "NcBwWSjFFWR6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "IF WE HAVE 3 HOMOLOGY GROUPS WE CAN MAKE RGB MOVIES OF THE BOTTLENECK DISTANCES CHANGING OVER TIME!!!\n",
        "\n",
        "This will only work with a single window size for time at each timestep\n",
        "\n",
        "For now, try animating plot_heatmap()\n",
        "\n",
        "Can I increase step and dx to reduce the number of positions and offsets to save computation time?\n",
        "I don't think so, they are about half the size of the patterns (nyquist frequency), so if step and dx were any larger we could see anomalies but not trends.\n",
        "Actually, doubling step to 50 (4 sizes) works fine! 3 is fine too but much less impressive\n",
        "\n",
        "I think the actual dx is 100m. Should probably go back and change in the video processing notebook and the data files. Or is it better to use 0-indexed integers for axes in math?\n",
        "\n",
        "Are the data files even accurate? dy looks larger than dx. Need to check the ashton paper for dx,dy,dt and size of domain. If these data files are bad, need to regenerate from new model runs :( Probably won't do this for the class project..."
      ],
      "metadata": {
        "id": "ZIegE3G5eoz9"
      },
      "id": "ZIegE3G5eoz9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not in this notebook: Make a figure with 8 subplots for the pretty argmax plots stacked over the noPonds scatterplots of the final frame of each video"
      ],
      "metadata": {
        "id": "SgTetbGqgBTa"
      },
      "id": "SgTetbGqgBTa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Below are functions for precomputing the distance plots across timesteps and animating them\n",
        "The animation should look like plot_heatmaps in the old notebook\n",
        "\n",
        "To do:\n",
        "\n",
        "* Refactor into:\n",
        "  * \"Pre-computation\" function with parameters:\n",
        "    * videoNum\n",
        "    * noPonds\n",
        "  * \"animation\" function with parameters:\n",
        "    * npz filename\n",
        "      * videoNum\n",
        "      * noPonds\n",
        "    * hspace\n",
        "    * hg_to_animate\n",
        "* I wish I could plot just one timestep with this method... not sure if any of the Gemini changes are problematic\n",
        "  * Gemini uses set_title instead of colorbar label\n",
        "  * not sure if I can/ how to animate the colorbar label...\n",
        "\n",
        "* Verify hspace with plot_heatmap() before animating\n",
        "* Fix order of yMin and yMax outputs, parameters and arguments in the old notebook"
      ],
      "metadata": {
        "id": "_09c61NVjA4C"
      },
      "id": "_09c61NVjA4C"
    },
    {
      "cell_type": "code",
      "source": [
        "def precompute(videoNum,noPondsStr=\"_noPonds\"):\n",
        "  '''\n",
        "  If you wish to animate a different video, you can change `videoNum`\n",
        "  noPondsStr = \"_noPonds\" # set to empty to use full point cloud\n",
        "  '''\n",
        "\n",
        "  fnBase = f\"jgrf217-sup-000{videoNum+1}-ms0{videoNum}{noPondsStr}\"\n",
        "  print(fnBase)\n",
        "  readin = np.load(f\"data/{fnBase}.npz\")\n",
        "  thisCoast = [readin[key] for key in readin.keys()]\n",
        "  readin.close()\n",
        "\n",
        "  # Calculate maxY and minY across all timesteps in thisCoast for consistent scatter plot limits\n",
        "  maxY = max([data_slice[:,1].max() for data_slice in thisCoast])\n",
        "  minY = min([data_slice[:,1].min() for data_slice in thisCoast])\n",
        "\n",
        "  # Calculate global min/max x for `thisCoast` to define constant x-axis for animation\n",
        "  global_min_x = min([data_slice[:,0].min() for data_slice in thisCoast])\n",
        "  global_max_x = max([data_slice[:,0].max() for data_slice in thisCoast])\n",
        "  global_x_range = global_max_x - global_min_x\n",
        "\n",
        "  # Define constant positions and offsets based on the global x-range\n",
        "  positions = dx_val * np.arange(global_x_range // dx_val + 2) + global_min_x\n",
        "  offsets = step_val * np.arange(1, maxWindow_val // step_val + 1) / 2\n",
        "  offsets = offsets[offsets >= minWindow_val / 2]\n",
        "  sizes = offsets * 2\n",
        "\n",
        "  # Use the same parameters for sliding_windows_par as in the last execution\n",
        "  dx_val = 50\n",
        "  maxWindow_val = 200\n",
        "  step_val = 50\n",
        "  minWindow_val = step_val # Default from sliding_windows_par\n",
        "\n",
        "  # Homology groups are constant (0 and 1 for 2D data)\n",
        "  homology_groups = [0, 1]\n",
        "\n",
        "  all_dists_per_timestep = []\n",
        "\n",
        "  print(\"Starting pre-computation for animation...\")\n",
        "  for i, data_timestep in enumerate(thisCoast):\n",
        "      print(f\"Processing timestep {i+1}/{len(thisCoast)}\", flush=True)\n",
        "\n",
        "      # Setup buffer for the current timestep's data\n",
        "      _, _, _, buff_i = setupBuff(data_timestep)\n",
        "\n",
        "      # Create a partial function for distsAtPos with fixed arguments (buff_i is specific to this timestep)\n",
        "      distsAtPos_partial = partial(distsAtPos, offsets=offsets, homologyGroups=homology_groups, buff=buff_i)\n",
        "\n",
        "      # Execute in parallel for each position\n",
        "      allPosDists_i = Parallel(n_jobs=-1, backend='threading')(\n",
        "          delayed(distsAtPos_partial)(pos) for pos in positions)\n",
        "\n",
        "      # Reshape the results into the final dists array\n",
        "      dists_i = np.array(allPosDists_i).transpose(2,1,0) # (num_homology_groups, num_offsets, num_positions)\n",
        "      all_dists_per_timestep.append(dists_i)\n",
        "\n",
        "  print(\"Pre-computation complete.\")\n",
        "\n",
        "  # Convert list to array for easier indexing\n",
        "  # Shape: (num_timesteps, num_homology_groups, num_offsets, num_positions)\n",
        "  all_dists_per_timestep = np.array(all_dists_per_timestep)\n",
        "  return fnBase, all_dists_per_timestep, positions, sizes, homology_groups, maxY, minY"
      ],
      "metadata": {
        "id": "9ghdmYoj155D"
      },
      "id": "9ghdmYoj155D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for videoNum in range(1,6):\n",
        "  for noPondsStr in [\"\", \"_noPonds\"]:\n",
        "    fnBase, all_dists, positions, sizes, homologyGroups, maxY, minY = precompute(videoNum, noPondsStr)\n",
        "\n",
        "    np.savez_compressed(f\"{fnBase}_dists.npz\", all_dists, positions, sizes, \\\n",
        "                          homologyGroups, maxY, minY)"
      ],
      "metadata": {
        "id": "rnBjGlU29DVb"
      },
      "id": "rnBjGlU29DVb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pWmo4Q0nbkU"
      },
      "source": [
        "def animate(videoNum, homologyGroups=None, noPondsStr=\"_noPonds\", hspace_val=-1):\n",
        "  '''\n",
        "  Choose a videoNum and homology group to animate (e.g., 0 for connected components, 1 for loops)\n",
        "  homologyGroups = [0,1] # Change this to 1 to animate for the other homology group\n",
        "  noPondsStr = \"_noPonds\" # set to empty to use full point cloud\n",
        "  hspace_val = -1 # vertical space between subplots - depends on yMax-yMin and len(sizes)\n",
        "                  # Verify hspace with plot_heatmap() before animating\n",
        "  '''\n",
        "\n",
        "  fnBase = f\"jgrf217-sup-000{videoNum+1}-ms0{videoNum}{noPondsStr}\"\n",
        "  print(fnBase)\n",
        "  readin = np.load(f\"data/{fnBase}.npz\")\n",
        "  thisCoast = [readin[key] for key in readin.keys()]\n",
        "  readin.close()\n",
        "  readin = np.load(f\"data/{fnBase}_dists.npz\")\n",
        "  thisCoast = [readin[key] for key in readin.keys()]\n",
        "  readin.close()\n",
        "\n",
        "  # Setup the figure and initial plot\n",
        "  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
        "\n",
        "  # Calculate constant x-extent for the heatmap and scatter plot\n",
        "  dx = positions[1] - positions[0]\n",
        "  x_extent = [positions[0] - dx / 2, positions[-1] + dx / 2]\n",
        "\n",
        "  # Calculate extent for imshow (y-axis is constant, x-axis is now also constant)\n",
        "  step_y_extent = sizes[1] - sizes[0] if len(sizes) > 1 else sizes[0] # Handle single window size case\n",
        "  y_extent = [sizes[0] - step_y_extent, sizes[-1]]\n",
        "  constant_extent = x_extent + y_extent\n",
        "\n",
        "  anims = []\n",
        "  if homologyGroups is None:\n",
        "    homologyGroups = range(2)\n",
        "  for hg_to_animate in homologyGroups:\n",
        "    # Initial data for the first frame\n",
        "    initial_dists = all_dists[0, hg_to_animate]\n",
        "    initial_data = thisCoast[0]\n",
        "\n",
        "    im = ax1.imshow(initial_dists, aspect='auto', origin='lower', extent=constant_extent,\n",
        "                    vmin=0, vmax=all_dists[:, hg_to_animate].max())\n",
        "    fig.colorbar(im, ax=ax1, orientation='horizontal', location='top', aspect=50) #label=f\"Bottleneck Distance for Homology Group {homology_groups[hg_to_animate]}\",\n",
        "    ax1.set_ylabel('Window Size')\n",
        "    ax1.set_title(f'Homology Group {homologyGroups[hg_to_animate]} - Timestep 1')\n",
        "    ax1.tick_params(\n",
        "        axis='x',          # changes apply to the x-axis\n",
        "        which='both',      # both major and minor ticks are affected\n",
        "        bottom=True,      # ticks along the bottom edge are off\n",
        "        top=False,         # ticks along the top edge are off\n",
        "        labelbottom=False) # labels along the bottom edge are off\n",
        "\n",
        "    sc = ax2.scatter(initial_data[:,0], initial_data[:,1], s=1)\n",
        "    ax2.set_xlabel('Position')\n",
        "    ax2.set_ylabel('Y')\n",
        "    ax2.set_aspect('equal', adjustable='box')\n",
        "    ax2.set_xlim(*x_extent) # Use the constant x-extent\n",
        "    scatpad = (maxY - minY) / 20\n",
        "    ax2.set_ylim([minY - scatpad, maxY + scatpad])\n",
        "\n",
        "    # hspace_val = -1.1 # As used in printAndPlot\n",
        "    plt.subplots_adjust(hspace=hspace_val)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Update function for the animation\n",
        "    def update(frame):\n",
        "        # Get pre-computed data for the current frame\n",
        "        dists_frame = all_dists[frame, hg_to_animate]\n",
        "        data_frame = thisCoast[frame]\n",
        "\n",
        "        # Update heatmap\n",
        "        im.set_data(dists_frame)\n",
        "        im.set_extent(constant_extent) # Use the constant extent\n",
        "\n",
        "        # Update scatter plot\n",
        "        sc.set_offsets(data_frame)\n",
        "        ax2.set_xlim(*x_extent) # Ensure x-axis of scatter plot matches heatmap (constant)\n",
        "        ax1.set_title(f'Homology Group {homologyGroups[hg_to_animate]} - Timestep {frame + 1}')\n",
        "\n",
        "        return [im, sc, ax1.title]\n",
        "\n",
        "    # Create the animation\n",
        "    anim = FuncAnimation(fig, update, frames=len(thisCoast), interval=200, blit=True)\n",
        "\n",
        "    class PillowWriterNG(PillowWriter):\n",
        "        def finish(self):\n",
        "                self._frames[0].save(\n",
        "                    self.outfile, save_all=True, append_images=self._frames[1:],\n",
        "                    duration=int(1000 / self.fps), loop=None)\n",
        "\n",
        "    anim.save(f\"{fnBase}_H{hg_to_animate}.gif\", writer=\"pillow\")#PillowWriterNG())\n",
        "\n",
        "    anims[hg_to_animate] = anim\n",
        "\n",
        "  return anims\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "2pWmo4Q0nbkU"
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
        "\n",
        "hspace_vals = [, , , , ,]\n",
        "for hspaceIdx, videoNum in enumerate(range(1,6)):\n",
        "  for noPondsStr in [\"\", \"_noPonds\"]:\n",
        "    anims = animate(videoNum, noPondsStr=noPondsStr, hspace_val=hspace_vals[hspaceIdx])\n",
        "    # Display the animation (Colab will render this automatically if %matplotlib inline and jshtml is set)\n",
        "    anims[0]\n",
        "    plt.show()\n",
        "    anims[1]\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OV7dBHJm8FuD"
      },
      "id": "OV7dBHJm8FuD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}