{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MBgmAcTyrX3W",
   "metadata": {
    "id": "MBgmAcTyrX3W"
   },
   "outputs": [],
   "source": [
    "import ripser, persim, warnings\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b34833-1120-44bc-9fb1-bb8b572c279c",
   "metadata": {
    "id": "a9b34833-1120-44bc-9fb1-bb8b572c279c"
   },
   "source": [
    "## Function that returns bottleneck/wasserstein distance and optionally plots persistence diagram matchings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b171094-ce93-4712-8e63-e8ae6e277063",
   "metadata": {
    "id": "2b171094-ce93-4712-8e63-e8ae6e277063"
   },
   "outputs": [],
   "source": [
    "def getDist(feature, homologyGroup, matching=False, dgm=False):\n",
    "  '''\n",
    "  Takes a 2D array with columns x,y\n",
    "  and integer for homology group\n",
    "  TODO: accept 3D time series\n",
    "  '''\n",
    "                  # Line has same width and number of X points as feature...          but with y values at zero\n",
    "  line = np.array([np.linspace(min(feature[:,0]),max(feature[:,0]),len(feature[:,0])),np.zeros_like(feature[:,1])])\n",
    "  feature_dgm = ripser.ripser(feature)['dgms'][homologyGroup]\n",
    "  line_dgm = ripser.ripser(line.T)['dgms'][homologyGroup]\n",
    "\n",
    "  # Ignore warnings for dgm with non-finite death times\n",
    "  with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", message=r\"dgm[12] has points with non-finite death times;ignoring those points\")\n",
    "    warnings.filterwarnings(\"ignore\", message=r\"invalid value encountered in subtract\\n  l1_diff = abs(u - v)\")\n",
    "    if dgm:\n",
    "      persim.bottleneck_matching(feature_dgm, line_dgm, persim.bottleneck( \\\n",
    "        feature_dgm, line_dgm, matching=True)[1], labels=['feature', 'line'])\n",
    "\n",
    "    if matching:\n",
    "      return feature_dgm, line_dgm, persim.bottleneck(feature_dgm, line_dgm, matching=True)[1]\n",
    "    else:\n",
    "      return persim.sliced_wasserstein(feature_dgm, line_dgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahoTqrQhIXry",
   "metadata": {
    "id": "ahoTqrQhIXry"
   },
   "source": [
    "## Helper functions for bugfixing and parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wHsLbjD0PVOz",
   "metadata": {
    "id": "wHsLbjD0PVOz"
   },
   "outputs": [],
   "source": [
    "def setupBuff(data):\n",
    "  '''\n",
    "  Since we have periodic boundary conditions, we need copy the point cloud on\n",
    "  each end of the domain before looping over the original middle section\n",
    "  * time, timeRange are not included in this function *\n",
    "  '''\n",
    "  if data.ndim==2:\n",
    "    x,y = data.T\n",
    "    xRange = x.max() - x.min()\n",
    "    lbuff, rbuff = data.copy(), data.copy()\n",
    "    lbuff[:, 0] -= xRange\n",
    "    rbuff[:, 0] += xRange\n",
    "    buff = np.vstack((lbuff, data, rbuff))\n",
    "  elif data.ndim==3:\n",
    "    # Assumes dims are time,x,y\n",
    "    x, y = data.reshape(data.shape[1]*data.shape[2],2).T\n",
    "    xRange = x.max() - x.min()\n",
    "    buff = np.zeros((data.shape[1]*data.shape[2],2))\n",
    "    buffx,buffy = buff.T\n",
    "    for t in range(data.shape[0]):\n",
    "      lbuff, rbuff = data[t].copy(), data[t].copy()\n",
    "      lbuff[:, 0] -= xRange\n",
    "      rbuff[:, 0] += xRange\n",
    "      buff[t*data.shape[1]:(t+1)*data.shape[1]] = np.vstack((lbuff, data[t], rbuff))\n",
    "  #buffx,buffy = buff.T\n",
    "  return x, y, xRange, buff#, buffx, buffy\n",
    "\n",
    "                                        # 2D is default\n",
    "def getWindow(pos, offset, buff, time=None, tPos=None, tOffset=None):\n",
    "  buffx = buff.T[0]\n",
    "  if buff.ndim==2:\n",
    "    window = buff[(buffx>pos-offset) & (buffx<pos+offset)]\n",
    "    # Try to prevent 1-cell disconnected components on the edges\n",
    "    # This is a rare edge case - this mostly doesn't do anything\n",
    "    # Doesn't seem to matter for homology groups greater than zero\n",
    "    window[:,1][window[:,0]==window[0,0]] = window[0,1].min()\n",
    "    window[:,1][window[:,0]==window[-1,0]] = window[-1,1].min()\n",
    "  elif buff.ndim==3:\n",
    "    raise ValueError(\"Windows for 3D time series not yet implemented\")\n",
    "    # TODO: figure out how to select 3D window\n",
    "    window = buff[(buffx>pos-offset) & (buffx<pos+offset)]\n",
    "    # Try to prevent 1-cell disconnected components on the edges\n",
    "  return window\n",
    "\n",
    "def distsAtPos(pos, offsets, homologyGroups, buff):\n",
    "  '''\n",
    "  Gets bottleneck distances at an alongshore position given window offsets, homology groups, and buffered data\n",
    "  '''\n",
    "  # print(pos, flush = True)\n",
    "  # Each parallel job will return a row of bottleneck distances for all offsets and homology groups\n",
    "  posDists = np.zeros((len(offsets), len(homologyGroups)))\n",
    "  for offsetIdx, offset in enumerate(offsets):\n",
    "    # TODO : 3D case\n",
    "    window = getWindow(pos, offset, buff)\n",
    "    for hgIdx,hg in enumerate(homologyGroups):\n",
    "        posDists[offsetIdx,hgIdx] = getDist(window, hg)\n",
    "  # Be careful of this indent! Otherwise it will return only the first offset\n",
    "  return posDists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_09c61NVjA4C",
   "metadata": {
    "id": "_09c61NVjA4C"
   },
   "source": [
    "## Below are functions for precomputing the distance plots across timesteps and animating them\n",
    "The animation should look like plot_heatmaps in the old notebook\n",
    "\n",
    "To do:\n",
    "\n",
    "* Refactor into:\n",
    "  * \"Pre-computation\" function with parameters:\n",
    "    * videoNum\n",
    "    * noPonds\n",
    "  * \"animation\" function with parameters:\n",
    "    * npz filename\n",
    "      * videoNum\n",
    "      * noPonds\n",
    "    * hspace\n",
    "    * hg_to_animate\n",
    "* I wish I could plot just one timestep with this method... not sure if any of the Gemini changes are problematic\n",
    "  * Gemini uses set_title instead of colorbar label\n",
    "  * not sure if I can/ how to animate the colorbar label...\n",
    "\n",
    "* Verify hspace with plot_heatmap() before animating\n",
    "* Fix order of yMin and yMax outputs, parameters and arguments in the old notebook\n",
    "* Merge/Use sliding_windows or sliding_windows_par in precompute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c0fb2-b51c-4623-ae6a-757d9ee50c00",
   "metadata": {
    "id": "9f4c0fb2-b51c-4623-ae6a-757d9ee50c00"
   },
   "source": [
    "## Function that loops over data and stores bottleneck distances in a higher order array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ghdmYoj155D",
   "metadata": {
    "id": "9ghdmYoj155D"
   },
   "outputs": [],
   "source": [
    "def precompute(videoNum,noPondsStr=\"_noPonds\"):\n",
    "  '''\n",
    "  If you wish to animate a different video, you can change `videoNum`\n",
    "  noPondsStr = \"_noPonds\" # set to empty to use full point cloud\n",
    "  '''\n",
    "\n",
    "  fnBase = f\"jgrf217-sup-000{videoNum+1}-ms0{videoNum}{noPondsStr}\"\n",
    "  print(fnBase)\n",
    "  readin = np.load(f\"data/{fnBase}.npz\")\n",
    "  thisCoast = [readin[key] for key in readin.keys()]\n",
    "  readin.close()\n",
    "\n",
    "  # Calculate maxY and minY across all timesteps in thisCoast for consistent scatter plot limits\n",
    "  maxY = max([data_slice[:,1].max() for data_slice in thisCoast])\n",
    "  minY = min([data_slice[:,1].min() for data_slice in thisCoast])\n",
    "\n",
    "  # Calculate global min/max x for `thisCoast` to define constant x-axis for animation\n",
    "  global_min_x = min([data_slice[:,0].min() for data_slice in thisCoast])\n",
    "  global_max_x = max([data_slice[:,0].max() for data_slice in thisCoast])\n",
    "  global_x_range = global_max_x - global_min_x\n",
    "\n",
    "  # Use the same parameters for sliding_windows_par as in the last execution\n",
    "  dx_val = 50\n",
    "  maxWindow_val = 200\n",
    "  step_val = 50\n",
    "  minWindow_val = step_val # Default from sliding_windows_par\n",
    "    \n",
    "  # Define constant positions and offsets based on the global x-range\n",
    "  positions = dx_val * np.arange(global_x_range // dx_val + 2) + global_min_x\n",
    "  offsets = step_val * np.arange(1, maxWindow_val // step_val + 1) / 2\n",
    "  offsets = offsets[offsets >= minWindow_val / 2]\n",
    "  sizes = offsets * 2\n",
    "\n",
    "  # Homology groups are constant (0 and 1 for 2D data)\n",
    "  homology_groups = [0, 1]\n",
    "\n",
    "  all_dists_per_timestep = []\n",
    "\n",
    "# TODO: Check lengths of inputs and match case for loops with different partial funcs\n",
    "  print(\"Starting pre-computation for animation...\")\n",
    "  for i, data_timestep in enumerate(thisCoast):\n",
    "      print(f\"Processing timestep {i+1}/{len(thisCoast)}\", flush=True)\n",
    "\n",
    "      # Setup buffer for the current timestep's data\n",
    "      buff_i = setupBuff(data_timestep)[3]\n",
    "\n",
    "      # Create a partial function for distsAtPos with fixed arguments (buff_i is specific to this timestep)\n",
    "      distsAtPos_partial = partial(distsAtPos, offsets=offsets, homologyGroups=homology_groups, buff=buff_i)\n",
    "\n",
    "      # Execute in parallel for each position\n",
    "      allPosDists_i = Parallel(n_jobs=-1, backend='threading')(\n",
    "          delayed(distsAtPos_partial)(pos) for pos in positions)\n",
    "\n",
    "      # Reshape the results into the final dists array\n",
    "      dists_i = np.array(allPosDists_i).transpose(2,1,0) # (num_homology_groups, num_offsets, num_positions)\n",
    "      all_dists_per_timestep.append(dists_i)\n",
    "\n",
    "  print(\"Pre-computation complete.\")\n",
    "\n",
    "  # Convert list to array for easier indexing\n",
    "  # Shape: (num_timesteps, num_homology_groups, num_offsets, num_positions)\n",
    "  all_dists_per_timestep = np.array(all_dists_per_timestep)\n",
    "  return fnBase, all_dists_per_timestep, positions, sizes, homology_groups, maxY, minY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NcBwWSjFFWR6",
   "metadata": {
    "id": "NcBwWSjFFWR6"
   },
   "source": [
    "## Ideas for more plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZIegE3G5eoz9",
   "metadata": {
    "id": "ZIegE3G5eoz9"
   },
   "source": [
    "IF WE HAVE 3 HOMOLOGY GROUPS WE CAN MAKE RGB MOVIES OF THE BOTTLENECK DISTANCES CHANGING OVER TIME!!!\n",
    "\n",
    "This will only work with a single window size for time at each timestep\n",
    "\n",
    "For now, try animating plot_heatmap()\n",
    "\n",
    "Can I increase step and dx to reduce the number of positions and offsets to save computation time?\n",
    "I don't think so, they are about half the size of the patterns (nyquist frequency), so if step and dx were any larger we could see anomalies but not trends.\n",
    "Actually, doubling step to 50 (4 sizes) works fine! 3 is fine too but much less impressive\n",
    "\n",
    "I think the actual dx is 100m. Should probably go back and change in the video processing notebook and the data files. Or is it better to use 0-indexed integers for axes in math?\n",
    "\n",
    "Are the data files even accurate? dy looks larger than dx. Need to check the ashton paper for dx,dy,dt and size of domain. If these data files are bad, need to regenerate from new model runs :( Probably won't do this for the class project..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SgTetbGqgBTa",
   "metadata": {
    "id": "SgTetbGqgBTa"
   },
   "source": [
    "Not in this notebook: Make a figure with 8 subplots for the pretty argmax plots stacked over the noPonds scatterplots of the final frame of each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2pWmo4Q0nbkU",
   "metadata": {
    "id": "2pWmo4Q0nbkU"
   },
   "outputs": [],
   "source": [
    "def animate(videoNum, noPondsStr=\"_noPonds\", homologyGroups=None, hspace_val=-1, save=True): \n",
    "  '''\n",
    "  Choose a videoNum and homology group to animate (e.g., 0 for connected components, 1 for loops)\n",
    "  homologyGroups = [0,1] # Change this to 1 to animate for the other homology group\n",
    "  noPondsStr = \"_noPonds\" # set to empty to use full point cloud\n",
    "  hspace_val = -1 # vertical space between subplots - depends on yMax-yMin and len(sizes)\n",
    "                  # Verify hspace with plot_heatmap() before animating\n",
    "  '''\n",
    "  if type(videoNum) is int:\n",
    "      fnBase = f\"jgrf217-sup-000{videoNum+1}-ms0{videoNum}{noPondsStr}\"\n",
    "      readin = np.load(f\"data/{fnBase}.npz\")\n",
    "  else:\n",
    "      fnBase = Path(videoNum).stem\n",
    "  print(fnBase)\n",
    "\n",
    "  thisCoast = [readin[key] for key in readin.keys()]\n",
    "  readin.close()\n",
    "  readin = np.load(f\"data/{fnBase}_dists.npz\")\n",
    "  all_dists, positions, sizes, homologyGroups, maxY, minY = [readin[key] for key in readin.keys()]\n",
    "  readin.close()\n",
    "\n",
    "  # Setup the figure and initial plot\n",
    "  fig, (ax1, ax2) = plt.subplots(2, 1)#, figsize=(10, 8))\n",
    "\n",
    "  # Calculate constant x-extent for the heatmap and scatter plot\n",
    "  dx = positions[1] - positions[0]\n",
    "  x_extent = [positions[0] - dx / 2, positions[-1] + dx / 2]\n",
    "\n",
    "  # Calculate extent for imshow (y-axis is constant, x-axis is now also constant)\n",
    "  step_y_extent = sizes[1] - sizes[0] if len(sizes) > 1 else sizes[0] # Handle single window size case\n",
    "  y_extent = [sizes[0] - step_y_extent, sizes[-1]]\n",
    "  constant_extent = x_extent + y_extent\n",
    "\n",
    "  if homologyGroups is None:\n",
    "    homologyGroups = range(1)\n",
    "  anims = [None]*len(homologyGroups)\n",
    "  for hg_to_animate in homologyGroups:\n",
    "    # TODO: modify plot_heatmap and run it here with a flag for animation outputs\n",
    "    # Initial data for the first frame\n",
    "    initial_dists = all_dists[0, hg_to_animate]\n",
    "    initial_data = thisCoast[0]\n",
    "\n",
    "    im = ax1.imshow(initial_dists, aspect='auto', origin='lower', extent=constant_extent,\n",
    "                    vmin=0, vmax=all_dists[:, hg_to_animate].max())\n",
    "    cb = fig.colorbar(im, ax=ax1, orientation='horizontal', label=f\"Bottleneck Distance for Homology Group {homology_groups[hg_to_animate]} at Time {frame+1}\",\\\n",
    "                      location='top', aspect=50)\n",
    "    ax1.set_ylabel('Window Size')\n",
    "    ax1.set_title(f'Homology Group {homologyGroups[hg_to_animate]} - Timestep 1')\n",
    "    ax1.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=True,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False) # labels along the bottom edge are off\n",
    "\n",
    "    sc = ax2.scatter(initial_data[:,0], initial_data[:,1], s=1)\n",
    "    ax2.set_xlabel('Position')\n",
    "    ax2.set_ylabel('Y')\n",
    "    ax2.set_aspect('equal', adjustable='box')\n",
    "    ax2.set_xlim(*x_extent) # Use the constant x-extent\n",
    "    scatpad = (maxY - minY) / 20\n",
    "    ax2.set_ylim([minY - scatpad, maxY + scatpad])\n",
    "\n",
    "    # hspace_val = -1.1 # As used in printAndPlot\n",
    "    plt.subplots_adjust(hspace=hspace_val)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Update function for the animation\n",
    "    def update(frame):\n",
    "        # Get pre-computed data for the current frame\n",
    "        dists_frame = all_dists[frame, hg_to_animate]\n",
    "        data_frame = thisCoast[frame]\n",
    "\n",
    "        # Update heatmap\n",
    "        im.set_data(dists_frame)\n",
    "        im.set_extent(constant_extent) # Use the constant extent\n",
    "\n",
    "        # Update scatter plot\n",
    "        sc.set_offsets(data_frame)\n",
    "        ax2.set_xlim(*x_extent) # Ensure x-axis of scatter plot matches heatmap (constant)\n",
    "        # ax1.set_title(f'Homology Group {homologyGroups[hg_to_animate]} - Timestep {frame + 1}')\n",
    "        cb.set_label(f\"Bottleneck Distance for Homology Group {homology_groups[hg_to_animate]} at Time {frame+1}\")\n",
    "\n",
    "        return [im, sc, cb]\n",
    "\n",
    "    # Create the animation\n",
    "    anim = FuncAnimation(fig, update, frames=len(thisCoast), interval=200, blit=True)\n",
    "\n",
    "    class PillowWriterNG(PillowWriter):\n",
    "        def finish(self):\n",
    "                self._frames[0].save(\n",
    "                    self.outfile, save_all=True, append_images=self._frames[1:],\n",
    "                    duration=int(1000 / self.fps), loop=None)\n",
    "\n",
    "    if save:\n",
    "        anim.save(f\"{fnBase}_H{hg_to_animate}_wasserstein.gif\", writer=\"pillow\")#PillowWriterNG())\n",
    "\n",
    "    anims[hg_to_animate] = anim\n",
    "\n",
    "  return anims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4750e3-8e67-4e48-bc85-f83b08070f52",
   "metadata": {},
   "source": [
    "### Function that animates precomputed files as they appear (Run in background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87a303-6b5f-451a-bdec-6f9f1758a959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from watchfiles import watch\n",
    "import threading\n",
    "\n",
    "hspace_vals = [-1.1, -1.1, -1, -1, -1]\n",
    "\n",
    "def watch_folder(folder=\"data\"):\n",
    "    for changes in watch(folder):\n",
    "        #     1:New path  # TODO: Should also check it's not a directory\n",
    "        if changes[0]==1 and changes[2].endswith(\".npz\"):\n",
    "            for videoNumStr in reversed(changes[2]):\n",
    "                if videoNumStr.isdigit(): break\n",
    "            try:\n",
    "                # Can't keep these outputs for display in stdout :(\n",
    "                anims = animate(changes[2], hspace_val=hspace_vals[int(videoNumStr)-1])\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"Error generating animation in background: {e}\")\n",
    "                \n",
    "# You can run this watcher in a background thread so your notebook remains responsive:\n",
    "watch_thread = threading.Thread(target=watch_folder, args=(\"data\",), daemon=True)\n",
    "watch_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe9657-0008-4f65-aad2-ee8c1d69343f",
   "metadata": {},
   "source": [
    "### Precompute files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rnBjGlU29DVb",
   "metadata": {
    "id": "rnBjGlU29DVb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for videoNum in range(1,6):\n",
    "  for noPondsStr in [\"\", \"_noPonds\"]:\n",
    "    fnBase, all_dists, positions, sizes, homologyGroups, maxY, minY = precompute(videoNum, noPondsStr)\n",
    "    np.savez_compressed(f\"data/{fnBase}_distsWasserstein.npz\", all_dists, positions, sizes, homologyGroups, maxY, minY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5fdd07-9886-4af8-9a44-1c4f8e5d583b",
   "metadata": {},
   "source": [
    "### Finally, run animations again (just to display them in the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OV7dBHJm8FuD",
   "metadata": {
    "id": "OV7dBHJm8FuD"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "\n",
    "# Already defined in watch_folder\n",
    "# hspace_vals = [-1.1, -1.1, -1, -1, -1]\n",
    "for hspaceIdx, videoNum in enumerate(range(1,6)):\n",
    "  for noPondsStr in [\"\", \"_noPonds\"]:                                                 # Don't forget!\n",
    "    anims = animate(videoNum, noPondsStr=noPondsStr, hspace_val=hspace_vals[hspaceIdx], save=False)\n",
    "    # Display the animation (Colab will render this automatically if %matplotlib inline and jshtml is set)\n",
    "    anims[0]\n",
    "    plt.show()\n",
    "    anims[1]\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "tda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
